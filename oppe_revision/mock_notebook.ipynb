{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torch.functional as F\nimport torch.nn as nn\n# from torchvision.utils /import make_grid, save_image\nfrom torchvision.utils import save_image, make_grid\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import transforms\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Available device is: {device}')\ntorch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:43:03.910861Z","iopub.execute_input":"2025-08-23T07:43:03.911082Z","iopub.status.idle":"2025-08-23T07:43:12.676506Z","shell.execute_reply.started":"2025-08-23T07:43:03.911058Z","shell.execute_reply":"2025-08-23T07:43:12.675768Z"}},"outputs":[{"name":"stdout","text":"Available device is: cuda\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7981c2fcb4b0>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"batch_size = 128\ndz = 128\nz_dim = dz\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(False)\nz_fixed= 128\nepochs = 20\nlr= 5e-4\nn_critic=1 \nclip_value= 0.01\nimg_size= 28\nchannels= 1\nimg_shape = (channels, img_size, img_size)\nimport os\nos.makedirs('wgan_dcgan', exist_ok= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:57:47.920912Z","iopub.execute_input":"2025-08-23T07:57:47.921180Z","iopub.status.idle":"2025-08-23T07:57:47.925746Z","shell.execute_reply.started":"2025-08-23T07:57:47.921162Z","shell.execute_reply":"2025-08-23T07:57:47.925077Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"## DataLoader\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\ntrain_data = MNIST(root='.', train= True, download= True, transform= transform)\ntrain_loader = DataLoader(train_data, batch_size= batch_size, shuffle= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:57:48.257580Z","iopub.execute_input":"2025-08-23T07:57:48.257842Z","iopub.status.idle":"2025-08-23T07:57:50.451042Z","shell.execute_reply.started":"2025-08-23T07:57:48.257824Z","shell.execute_reply":"2025-08-23T07:57:50.450206Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 34.3MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 988kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 9.92MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 11.1MB/s]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.init_size = img_size//4\n        self.fc = nn.Linear(z_dim, 128*self.init_size*self.init_size)\n        self.conv_block = nn.Sequential(\n            nn.BatchNorm2d(128),\n            nn.ConvTranspose2d(128, 64, kernel_size= 4, stride= 2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 1, kernel_size= 4, stride= 2, padding= 1),\n            nn.Tanh()\n        )\n        return\n\n    def forward(self, z):\n        x = self.fc(z)\n        x = x.view(z.size(0), 128, self.init_size, self.init_size)\n        return self.conv_block(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:58:39.055741Z","iopub.execute_input":"2025-08-23T07:58:39.056710Z","iopub.status.idle":"2025-08-23T07:58:39.062601Z","shell.execute_reply.started":"2025-08-23T07:58:39.056674Z","shell.execute_reply":"2025-08-23T07:58:39.061842Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"### critric\nclass Critic(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(1, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n            nn.Flatten(),\n            nn.Linear(128*7*7, 1)\n        )\n        return\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:58:39.698810Z","iopub.execute_input":"2025-08-23T07:58:39.699057Z","iopub.status.idle":"2025-08-23T07:58:39.703815Z","shell.execute_reply.started":"2025-08-23T07:58:39.699038Z","shell.execute_reply":"2025-08-23T07:58:39.703165Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"generator = Generator().to(device)\ncritic = Critic().to(device)\n\n## optimizers \ng_optim = optim.RMSprop(generator.parameters(), lr= lr)\nc_optim = optim.RMSprop(critic.parameters(), lr= lr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:00:01.240080Z","iopub.execute_input":"2025-08-23T08:00:01.240788Z","iopub.status.idle":"2025-08-23T08:00:01.257887Z","shell.execute_reply.started":"2025-08-23T08:00:01.240764Z","shell.execute_reply":"2025-08-23T08:00:01.257364Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"## tranining loop\n## most critical for every loop\nfor epoch in range(1, epochs+1):\n    for i, (real_img, _) in enumerate(train_loader):\n        real_imgs = real_img.to(device)\n        b_size = real_imgs.size(0)\n\n        ## training critic\n        for _ in range(n_critic):\n            z= torch.randn(b_size, z_dim, device= device)\n            fake_imgs = generator(z)\n\n            loss_c = -torch.mean(critic(real_imgs)) + torch.mean(critic(fake_imgs.detach()))\n\n            c_optim.zero_grad()\n            loss_c.backward()\n            c_optim.step()\n            # weight clipping fo rLipschitz constraint\n            for p in critic.parameters():\n                p.data.clamp_(-clip_value, clip_value)\n\n    ## training the generator\n    z = torch.randn(b_size, z_dim, device= device)\n    gen_imgs = generator(z)\n    loss_g = -torch.mean(critic(gen_imgs))\n    g_optim.zero_grad()\n    loss_g.backward()\n    g_optim.step()\n\n    if epoch % 1 ==0:\n        print(f'[Epoch {epoch}/{epochs} [Batch {i}/{len(train_loader)}'\n              f'[Critic: {loss_c.item():.4f}] [Gen: {loss_g.item():.4f}]')\n\n\n    # save samples every epoch\n    generator.eval()\n    with torch.no_grad():\n        z = torch.randn(64, z_dim, device= device)\n        samples = generator(z)\n        samples = samples * 0.5 + 0.5\n        save_image(samples, f'wgan_dcgan/epoch_{epoch}.png', nrow= 8)\n    generator.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:23:28.024048Z","iopub.execute_input":"2025-08-23T08:23:28.024300Z","iopub.status.idle":"2025-08-23T08:27:13.183302Z","shell.execute_reply.started":"2025-08-23T08:23:28.024281Z","shell.execute_reply":"2025-08-23T08:27:13.182748Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1/20 [Batch 468/469[Critic: -0.4514] [Gen: 0.0808]\n[Epoch 2/20 [Batch 468/469[Critic: -0.4302] [Gen: 0.0458]\n[Epoch 3/20 [Batch 468/469[Critic: -0.4241] [Gen: -0.0419]\n[Epoch 4/20 [Batch 468/469[Critic: -0.4668] [Gen: 0.0656]\n[Epoch 5/20 [Batch 468/469[Critic: -0.5180] [Gen: 0.1051]\n[Epoch 6/20 [Batch 468/469[Critic: -0.4410] [Gen: 0.0640]\n[Epoch 7/20 [Batch 468/469[Critic: -0.4582] [Gen: 0.0368]\n[Epoch 8/20 [Batch 468/469[Critic: -0.5003] [Gen: 0.0978]\n[Epoch 9/20 [Batch 468/469[Critic: -0.3846] [Gen: 0.0895]\n[Epoch 10/20 [Batch 468/469[Critic: -0.3881] [Gen: 0.0827]\n[Epoch 11/20 [Batch 468/469[Critic: -0.4477] [Gen: 0.0117]\n[Epoch 12/20 [Batch 468/469[Critic: -0.4478] [Gen: 0.0343]\n[Epoch 13/20 [Batch 468/469[Critic: -0.4490] [Gen: 0.0415]\n[Epoch 14/20 [Batch 468/469[Critic: -0.4025] [Gen: 0.0375]\n[Epoch 15/20 [Batch 468/469[Critic: -0.4466] [Gen: 0.0518]\n[Epoch 16/20 [Batch 468/469[Critic: -0.3661] [Gen: 0.0504]\n[Epoch 17/20 [Batch 468/469[Critic: -0.3853] [Gen: 0.0372]\n[Epoch 18/20 [Batch 468/469[Critic: -0.3892] [Gen: 0.0117]\n[Epoch 19/20 [Batch 468/469[Critic: -0.3774] [Gen: 0.0095]\n[Epoch 20/20 [Batch 468/469[Critic: -0.3997] [Gen: 0.0422]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Question 1: Dataset size and Imbalance","metadata":{}},{"cell_type":"code","source":"dict_class = {int(x.split(' ')[0]): 0 for x in train_data.classes}\nprint(dict_class)\nfor _, y in train_data:\n    dict_class[y] += 1\nprint(dict_class)\nmax_class = (-1, -1)\nmin_class = (-1, len(train_data))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:36:50.424706Z","iopub.execute_input":"2025-08-23T08:36:50.424936Z","iopub.status.idle":"2025-08-23T08:37:00.055964Z","shell.execute_reply.started":"2025-08-23T08:36:50.424920Z","shell.execute_reply":"2025-08-23T08:37:00.055345Z"}},"outputs":[{"name":"stdout","text":"{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"## printing post transform training batch\nfor (real_imgs, _) in train_loader:\n    # print(real_imgs)\n    x = real_imgs\n    mu = x.mean()\n    sigma = x.std()\n    mi = x.min()\n    mx = x.min()\n    p = (x.abs() <= 0.5).float().mean().item()\n    # print('mean', torch.mean(real_imgs))\n    print(f'mu {mu} sigma {sigma} min {mi} max {mx} p {p}')\n    # print('signma', torch.)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:49:51.652868Z","iopub.execute_input":"2025-08-23T08:49:51.653124Z","iopub.status.idle":"2025-08-23T08:49:51.684786Z","shell.execute_reply.started":"2025-08-23T08:49:51.653105Z","shell.execute_reply":"2025-08-23T08:49:51.684191Z"}},"outputs":[{"name":"stdout","text":"mu -0.7486591935157776 sigma 0.603895902633667 min -1.0 max -1.0 p 0.0515485480427742\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"for k, v in dict_class.items():\n    if v > max_class[1]:\n        max_class = (k, v)\n    if v < min_class[1]:\n        min_class = (k, v)\nprint(max_class,min_class)\n\ntotal = sum(dict_class.values())\nprint('total items are:', total)\ndelta = max_class[1] - min_class[1]\nprint(delta)\nimbalance = (delta/(0.1 * total) ) * 100\nprint('Total imbalance is: ', imbalance)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:37:00.056890Z","iopub.execute_input":"2025-08-23T08:37:00.057228Z","iopub.status.idle":"2025-08-23T08:37:00.062089Z","shell.execute_reply.started":"2025-08-23T08:37:00.057210Z","shell.execute_reply":"2025-08-23T08:37:00.061549Z"}},"outputs":[{"name":"stdout","text":"(1, 6742) (5, 5421)\ntotal items are: 60000\n1321\nTotal imbalance is:  22.01666666666667\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"Question 3: Model size and memory","metadata":{}},{"cell_type":"code","source":"# computing total number of learnable parameters\ng_param_count = sum(p.numel() for p in generator.parameters() if p.requires_grad)\nc_param_count = sum(p.numel() for p in critic.parameters() if p.requires_grad)\nprint(f'Total parameters in g: {g_param_count} and critic: {c_param_count}')\nMB = 4*(g_param_count + c_param_count) / 1e6\nprint(MB)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:55:08.678806Z","iopub.execute_input":"2025-08-23T08:55:08.679319Z","iopub.status.idle":"2025-08-23T08:55:08.684362Z","shell.execute_reply.started":"2025-08-23T08:55:08.679295Z","shell.execute_reply":"2025-08-23T08:55:08.683578Z"}},"outputs":[{"name":"stdout","text":"Total parameters in g: 941633 and critic: 138817\n4.3218\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"Question 4: One training cycle delta","metadata":{}},{"cell_type":"code","source":"def get_params_vector(model):\n    return torch.cat([p.detach().view(-1) for p in model.parameters()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:20:52.620544Z","iopub.execute_input":"2025-08-23T09:20:52.621035Z","iopub.status.idle":"2025-08-23T09:20:52.624755Z","shell.execute_reply.started":"2025-08-23T09:20:52.621012Z","shell.execute_reply":"2025-08-23T09:20:52.624090Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"## one training cycle rewritting\nq = 5\nfor epoch in range(1, epochs +1):\n    for i, (real_imgs, _) in enumerate(train_loader):\n        real_imgs = real_imgs.to(device)\n        b_size = real_imgs.size(0)\n\n        ## training the critic\n        ld = 0\n        critic_param_before = get_params_vector\n        for _ in range(q):\n            z = torch.randn(b_size, z_dim, device= device)\n            fake_imgs = generator(z)\n            loss_c = -torch.mean(critic(real_imgs)) +  torch.mean(critic(fake_imgs.detach()))\n            ld += loss_c.item()\n            c_optim.zero_grad()\n            loss_c.backward()\n            c_optim.step()\n            print(f'ld {ld} loss: {loss_c.item()}')\n\n        ## generator thing\n        z = torch.randn(b_size, z_dim, device= device)\n        fake_imgs = generator(z)\n        loss_g = torch.mean(critic(fake_imgs))\n\n        g_optim.zero_grad()\n        loss_g.backward()\n        g_optim.step()\n            # break\n        # break\n    break\n                                 \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:11:41.493929Z","iopub.execute_input":"2025-08-23T09:11:41.494675Z","iopub.status.idle":"2025-08-23T09:12:04.545106Z","shell.execute_reply.started":"2025-08-23T09:11:41.494651Z","shell.execute_reply":"2025-08-23T09:12:04.544544Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"","metadata":{}}]}